import streamlit as st
import pandas as pd
import numpy as np
import joblib
from datetime import datetime, timedelta
from random import randint
from zoneinfo import ZoneInfo
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
from PIL import Image
from sklearn.metrics import (
    f1_score, recall_score, precision_score, accuracy_score,
    confusion_matrix, ConfusionMatrixDisplay
)
from utils.preprocessing import (
    preprocess_common,
    preprocess_for_attente,
    preprocess_for_hospitalisation,
    preprocess_for_moyenne
)

st.set_page_config(page_title="Projet Urgences", layout="wide")

@st.cache_data
def load_data():
    return pd.read_excel("data/liste_sejours_new.xlsx")

@st.cache_resource
def load_model(path):
    return joblib.load(path)

df_raw = load_data()
df_cleaned = preprocess_common(df_raw.copy())
df_nona = df_cleaned[
    ~df_cleaned.map(lambda x: isinstance(x, str) and x.strip().lower() == "nan")
]

# Initialiser les valeurs alÃ©atoires une seule fois
if "nb_present" not in st.session_state:
    st.session_state["nb_present"] = np.random.randint(20, 80)
if "salle_ioa" not in st.session_state:
    st.session_state["salle_ioa"] = np.random.randint(1, 10)
if "salle_med" not in st.session_state:
    st.session_state["salle_med"] = np.random.randint(2, 15)

tab0, tab1, tab2, tab3, tab4, tab5 = st.tabs(["ðŸ Introduction", "ðŸ“Š Data Visualisation", "ðŸ“ˆ Estimation moyenne", "ðŸ¤– Temps de passage", "ðŸ¥ Hospitalisation" , "ðŸ”š Conclusion"])

with tab0:
    st.header("ðŸ’¡ PrÃ©sentation du projet")
    
    subtab1, subtab2 = st.tabs(["ðŸ‘¥ L'Ã©quipe et la vision", "ðŸ¥ DonnÃ©es & parcours patient"])

    with subtab1:
        st.markdown("### ðŸŽ¯ Les membres du groupe et leurs objectifs")
        st.markdown("- **Marine** : souhaite travailler comme *Data Analyst/Scientist* dans le domaine mÃ©dical â€“ ce projet illustre bien les missions possibles dans ce secteur.")
        st.markdown("- **Pascal** : en reconversion professionnelle, il vise un poste de consultant en amÃ©lioration continue, en sâ€™appuyant sur les outils de la data.")
        st.markdown("- **RÃ©mi** : chef de projet informatique dans un hÃ´pital, il veut intÃ©grer lâ€™analyse de donnÃ©es dans son environnement professionnel et mettre en Å“uvre concrÃ¨tement ce projet au GHPSO.")
        st.markdown("- **Cansu** : Ã©galement en reconversion professionnelle, elle souhaite devenir *Data Analyst* dans son Ã©tablissement actuel.")

        
        st.markdown("### ðŸ” Sources dâ€™inspiration et analyse de pratiques externes")
        st.markdown("- Observation de bonnes pratiques dans dâ€™autres structures de santÃ© :\n"
            "    - Des Ã©tablissements comme lâ€™**AP-HP** ou la **Clinique Saint Martin Ã  Caen** affichent dÃ©jÃ  le temps dâ€™attente sur leur site.\n"
            "    - Nous avons aussi Ã©tudiÃ© les indicateurs utilisÃ©s au **QuÃ©bec**, trÃ¨s dÃ©taillÃ©s, mais difficilement exploitables ici en lâ€™absence de certaines donnÃ©es.\n"
            "    - La **Cour des comptes**, dans son rapport de novembre 2024 sur *â€œLâ€™accueil et le traitement des urgences Ã  lâ€™hÃ´pitalâ€*, recommande dâ€™ailleurs de sâ€™inspirer des pratiques de la mÃ©decine dâ€™urgence quÃ©bÃ©coise.")


        st.markdown("### ðŸ¤ Alignement dâ€™Ã©quipe et vision partagÃ©e")
        st.markdown("- Mise en place dâ€™un **vision boat** dÃ¨s la premiÃ¨re rÃ©union pour :\n"
            "    - Clarifier les objectifs individuels et collectifs\n"
            "    - Donner du sens au projet\n"
            "    - CrÃ©er une dynamique de groupe motivante et alignÃ©e")

    with subtab2:
        st.markdown("### ðŸ§­ Parcours dâ€™un patient aux urgences")
        st.markdown("1. Accueil par lâ€™**IOA** (*InfirmierÂ·e dâ€™Orientation et dâ€™Accueil*)")
        st.markdown("2. **TRI** (Ã©valuation du niveau de gravitÃ©)")
        st.markdown("3. Passage devant le **mÃ©decin**")
        st.markdown("4. Orientation vers la **sortie** ou vers une **hospitalisation**")

        st.markdown("### ðŸ“¦ Contenu du jeu de donnÃ©es")
        st.markdown("- Heures dâ€™entrÃ©e et de sortie aux urgences")
        st.markdown("- Temps dâ€™attente Ã  chaque Ã©tape (IOA, consultation mÃ©dicaleâ€¦)")
        st.markdown("- Informations sur les patients : Ã¢ge, motif de venue, discipline mÃ©dicale")
        st.markdown("- Niveau de gravitÃ© via la colonne **Tri IOA**")

        st.markdown("### âš ï¸ ProblÃ¨mes identifiÃ©s lors de lâ€™analyse")
        st.markdown("- Valeurs manquantes ou incohÃ©rentes (ex : Ã¢ges extrÃªmes, `#VALEURMULTI`)")
        st.markdown("- Formats de dates non uniformes")

        st.markdown("### ðŸ§¹ Nettoyage et prÃ©paration des donnÃ©es")
        st.markdown("- Uniformisation des colonnes")
        st.markdown("- Conversion des dates au format `datetime`")
        st.markdown("- Suppression des valeurs aberrantes")
        st.markdown("- CrÃ©ation de nouvelles variables (ex : dÃ©lais entre chaque Ã©tape)")

        st.markdown("### ðŸ“Š Tendances dÃ©gagÃ©es (analyse exploratoire)")
        st.markdown("- Le temps passÃ© aux urgences varie selon :\n"
            "    - Le **niveau de tri IOA**\n"
            "    - La **discipline mÃ©dicale**\n"
            "    - Le **motif de venue**")
        st.markdown("- Pics dâ€™affluence identifiÃ©s :\n"
            "  - Ã€ certaines **heures de la journÃ©e**\n"
            "  - Ã€ certains **jours de la semaine**")

with tab1:
    st.title("ðŸ“Š Analyse exploratoire des donnÃ©es urgences")
    st.subheader("1. Distribution des variables clÃ©s")

    # --- CrÃ©ation des figures ---
    colors = px.colors.sequential.Magma

    # Ã‚ge
    fig_age = px.histogram(
        df_cleaned,
        x="Age_Moyen_Sejour_Annees",
        nbins=15,
        title="Distribution de l'Ã¢ge",
        color_discrete_sequence=px.colors.qualitative.T10,
    )
    fig_age.update_layout(yaxis_title="Nombre de sÃ©jours", bargap=0.05)

    # Tri_IOA
    ordre_tri = ['Tri 1', 'Tri 2', 'Tri 3A', 'Tri 3B', 'Tri 4', 'Tri 5']
    df_tri = df_cleaned["Tri_IOA"].value_counts().reindex(ordre_tri).reset_index()
    df_tri.columns = ["Tri_IOA", "count"]
    fig_tri = px.bar(
        df_tri,
        x="Tri_IOA",
        y="count",
        title="Distribution du Tri_IOA",
        color = "Tri_IOA",
        color_discrete_sequence=px.colors.qualitative.T10,
    )
    fig_tri.update_layout(yaxis_title="Nombre de sÃ©jours")

    # Motif de recours
    df_motif = df_cleaned[
    df_cleaned["Motif_de_recours"].apply(lambda x: isinstance(x, str) and x.strip().lower() != "nan")]["Motif_de_recours"].value_counts().reset_index().copy()
    df_motif.columns = ["Motif_de_recours", "count"]
    fig_motif = px.bar(
        df_motif,
        x="Motif_de_recours",
        y="count",
        title="RÃ©partition des motifs de recours",
        color='Motif_de_recours',
        color_discrete_sequence=px.colors.qualitative.T10
    )
    fig_motif.update_layout(
        yaxis_title="Nombre de sÃ©jours",
        xaxis_tickangle=45
    )

    # Affichage des trois figures
    col1, col2 = st.columns(2)
    with col1:
        st.plotly_chart(fig_age, use_container_width=True)
    with col2:
        st.plotly_chart(fig_tri, use_container_width=True)

    st.plotly_chart(fig_motif, use_container_width=True)

        #Temps d'attente et variable 
    bins = [0, 18, 30, 60, 80, 120]
    labels = ['0-18', '19-30', '31-60', '61-80', '81-120']
    
    # Copie pour ne pas impacter df_cleaned
    df_graph = df_cleaned.copy()

        # SÃ©lection du type de dÃ©lai Ã  visualiser
    delais = {
        'DÃ©lai entre entrÃ©e et IOA (h)': 'Delai_entree_IOA_heure',
        'DÃ©lai entre entrÃ©e et mÃ©decin (h)': 'Delai_entree_MED_heure',
        'DurÃ©e totale (h)': 'Duree_totale_heure',
    }

    choix_delai = st.selectbox("Choisir le type de dÃ©lai Ã  visualiser :", list(delais.keys()))
    colonne_duree = delais[choix_delai]

    # PrÃ©paration des catÃ©gories de regroupement
    categorie_options = {
        'Ã‚ge': 'age',
        'Tri IOA': 'Tri_IOA',
        'Motif de recours': 'Motif_de_recours'
    }
    df_graph['age'] = pd.cut(df_graph['Age_Moyen_Sejour_Annees'], bins=bins, labels=labels, right=True)

    # Nettoyage
    df_graph = df_graph[df_graph['Motif_de_recours'].astype(str).str.strip().str.lower() != "nan"]
    df_graph = df_graph[df_graph['Tri_IOA'].astype(str).str.strip().str.lower() != "nan"]

    # Conversion en timedelta
    colonnes_timedelta = ['Duree_totale_heure', 'Delai_entree_IOA_heure', 'Delai_entree_MED_heure']
    for col in colonnes_timedelta:
        df_graph[col] = pd.to_timedelta(df_graph[col], unit='h', errors='coerce')

    # Filtrage des valeurs aberrantes
    df_graph = df_graph[
        df_graph['Duree_totale_heure'].notna() &
        df_graph['Delai_entree_IOA_heure'].notna() &
        df_graph['Delai_entree_MED_heure'].notna()
    ]

    df_graph = df_graph[
        (df_graph['Duree_totale_heure'] > pd.Timedelta(minutes=0)) &
        (df_graph['Duree_totale_heure'] < pd.Timedelta(hours=36)) &
        (df_graph['Delai_entree_IOA_heure'] > pd.Timedelta(minutes=0)) &
        (df_graph['Delai_entree_IOA_heure'] < pd.Timedelta(hours=1, minutes=12)) &
        (df_graph['Delai_entree_MED_heure'] > pd.Timedelta(minutes=0)) &
        (df_graph['Delai_entree_MED_heure'] < pd.Timedelta(hours=14, minutes=7))
    ]

    # Transformation de la colonne choisie en heures
    df_graph[colonne_duree] = df_graph[colonne_duree].dt.total_seconds() / 3600

    # Affichage des boxplots pour chaque variable de regroupement
    for categorie_affichee, categorie in categorie_options.items():
        fig = px.box(
            df_graph,
            x=categorie,
            y=colonne_duree,
            points=False,
            title=f"{choix_delai} selon {categorie_affichee}",
            color_discrete_sequence=px.colors.qualitative.T10,
            category_orders={
                'age': ['0-18', '19-30', '31-60', '61-80', '81-120'],
                'Tri_IOA': ['Tri 1', 'Tri 2', 'Tri 3A', 'Tri 3B', 'Tri 4', 'Tri 5']
            }
        )
        fig.update_layout(
            xaxis_title=categorie_affichee,
            yaxis_title="Heures",
            height=400
        )
        if categorie == 'Motif_de_recours':
            fig.update_layout(xaxis_tickangle=40)
        st.plotly_chart(fig, use_container_width=True)

    # ðŸ”¥ Carte thermique des arrivÃ©es - version amÃ©liorÃ©e
    st.subheader("2. Carte thermique des arrivÃ©es")

    # PrÃ©parer les donnÃ©es groupÃ©es
    heatmap_data = df_cleaned.groupby(["Jour", "Heure_Entree"]).size().reset_index(name="count")

    # Mapper les jours pour quâ€™ils soient affichÃ©s correctement dans l'ordre
    jours_mapping = {
        0: "Lundi", 1: "Mardi", 2: "Mercredi", 3: "Jeudi",
        4: "Vendredi", 5: "Samedi", 6: "Dimanche"
    }
    heatmap_data["JourNom"] = heatmap_data["Jour"].map(jours_mapping)

    # CrÃ©ation de la heatmap Plotly
    fig_heatmap = px.density_heatmap(
        heatmap_data,
        x="Heure_Entree",
        y="JourNom",
        z="count",
        color_continuous_scale="RdBu_r",  # proche de coolwarm
        title="Carte thermique des arrivÃ©es par jour et heure",
        nbinsx=24,
        category_orders={"JourNom": ["Lundi", "Mardi", "Mercredi", "Jeudi", "Vendredi", "Samedi", "Dimanche"]}
    )

    fig_heatmap.update_layout(
        xaxis=dict(
            title="Heure de la journÃ©e",
            tickmode="linear",
            tick0=0,
            dtick=1
        ),
        xaxis_title="Heure de la journÃ©e",
        yaxis_title="Jour de la semaine",
        height=600,
        width=1200,
        margin=dict(l=40, r=40, t=50, b=40)
    )
    st.plotly_chart(fig_heatmap, use_container_width=False)


    #Matrice de corrÃ©lation 
    st.subheader("3. Matrice de corrÃ©lation ")
    numeric_df = df_cleaned.select_dtypes(include=np.number)
    cor = numeric_df.corr(method='spearman')
    mask = np.tril(np.ones_like(cor, dtype=bool))
    cor_masked = cor.where(mask)
    fig = px.imshow(cor_masked, aspect="auto", title="Matrice de corrÃ©lation", color_continuous_scale="RdBu_r")

    st.plotly_chart(fig, use_container_width=True)

    
    st.subheader("4. Analyse des valeurs manquantes")

    import plotly.graph_objects as go

     # Calcul des pourcentages de sÃ©jours avec valeurs manquantes
    pourcent_sortie_sejour = (
        df_cleaned[df_cleaned["Date_Heure_Sortie_Urgences"].isna()]
        .groupby(df_cleaned["Date_Heure_Entree_Sejour"].dt.year)
        .size()
        / df_cleaned.groupby(df_cleaned["Date_Heure_Entree_Sejour"].dt.year).size()
        * 100
    )

    pourcent_PEC_MED = (
        df_cleaned[df_cleaned["Date_Heure_PEC_MED"].isna()]
        .groupby(df_cleaned["Date_Heure_Entree_Sejour"].dt.year)
        .size()
        / df_cleaned.groupby(df_cleaned["Date_Heure_Entree_Sejour"].dt.year).size()
        * 100
    )

    pourcent_PEC_IOA = (
        df_cleaned[df_cleaned["Date_Heure_PEC_IOA"].isna()]
        .groupby(df_cleaned["Date_Heure_Entree_Sejour"].dt.year)
        .size()
        / df_cleaned.groupby(df_cleaned["Date_Heure_Entree_Sejour"].dt.year).size()
        * 100
    )

    # CrÃ©ation du graphique Plotly
    fig = go.Figure()

    fig.add_trace(
        go.Scatter(
            x=pourcent_sortie_sejour.index,
            y=pourcent_sortie_sejour.values,
            mode="lines+markers",
            name="Sortie SÃ©jour Manquant",
        )
    )

    fig.add_trace(
        go.Scatter(
            x=pourcent_PEC_MED.index,
            y=pourcent_PEC_MED.values,
            mode="lines+markers",
            name="PEC MED Manquant",
        )
    )

    fig.add_trace(
        go.Scatter(
            x=pourcent_PEC_IOA.index,
            y=pourcent_PEC_IOA.values,
            mode="lines+markers",
            name="PEC IOA Manquant",
        )
    )

    # Mise Ã  jour de la mise en page du graphique
    fig.update_layout(
        title_text="Pourcentage de SÃ©jours avec Valeurs Manquantes par AnnÃ©e",
        xaxis_title="AnnÃ©e",
        yaxis_title="Pourcentage (%)",
        height=600,
        width=800,
    )

    # Affichage dans Streamlit
    st.title("Analyse des SÃ©jours avec Valeurs Manquantes")
    st.plotly_chart(fig, use_container_width=True)

    # Analyse de l'impact de la dispersion entre 2021_2024 et 2023_2024
    #Creation de dataset pour 2023-2024 et 2021-2024 :
    df_2324 = df_cleaned[df_cleaned['Date_Heure_Entree_Sejour'].dt.year.isin([2023,2024])].copy()
    df_2124 = df_cleaned[df_cleaned['Date_Heure_Entree_Sejour'].dt.year.isin([2021,2022,2023,2024])].copy()
    
    from plotly.subplots import make_subplots
   

    fig = make_subplots(rows=1, cols=8, shared_xaxes=True)

    # Trace des boxplots pour les 4 durees
    df_2124['Duree_totale_heure'] = pd.to_timedelta(df_2124['Duree_totale_heure'], unit='h')
    df_2324['Duree_totale_heure'] = pd.to_timedelta(df_2324['Duree_totale_heure'], unit='h')

    df_2124['Delai_entree_IOA_heure'] = pd.to_timedelta(df_2124['Delai_entree_IOA_heure'], unit='h')
    df_2324['Delai_entree_IOA_heure'] = pd.to_timedelta(df_2324['Delai_entree_IOA_heure'], unit='h')

    df_2124['Delai_IOA_MED_heure'] = pd.to_timedelta(df_2124['Delai_IOA_MED_heure'], unit='h')
    df_2324['Delai_IOA_MED_heure'] = pd.to_timedelta(df_2324['Delai_IOA_MED_heure'], unit='h')

    df_2124['Delai_MED_sortie_heure'] = pd.to_timedelta(df_2124['Delai_MED_sortie_heure'], unit='h')
    df_2324['Delai_MED_sortie_heure'] = pd.to_timedelta(df_2324['Delai_MED_sortie_heure'], unit='h')
    fig.add_trace(go.Box(y=(df_2124['Duree_totale_heure'].dt.total_seconds() / 3600).round(3), name='Duree_totale 2124'), row=1, col=1)
    fig.add_trace(go.Box(y=(df_2324['Duree_totale_heure'].dt.total_seconds()/3600).round(3), name='Duree_Totale 2324'), row=1, col=2)

    fig.add_trace(go.Box(y=(df_2124['Delai_entree_IOA_heure'].dt.total_seconds()/3600).round(3), name='Delai_entree_IOA 2124'), row=1, col=3)
    fig.add_trace(go.Box(y=(df_2324['Delai_entree_IOA_heure'].dt.total_seconds()/3600).round(3), name='Delai_entree_IOA 2324'), row=1, col=4)

    fig.add_trace(go.Box(y=(df_2124['Delai_IOA_MED_heure'].dt.total_seconds()/3600).round(3), name='Delai_IOA_MED 2124'), row=1, col=5)
    fig.add_trace(go.Box(y=(df_2324['Delai_IOA_MED_heure'].dt.total_seconds()/3600).round(3), name='Delai_IOA_MED 2324'), row=1, col=6)

    fig.add_trace(go.Box(y=(df_2124['Delai_MED_sortie_heure'].dt.total_seconds()/3600).round(3), name='Delai_MED_sortie 2124'), row=1, col=7)
    fig.add_trace(go.Box(y=(df_2324['Delai_MED_sortie_heure'].dt.total_seconds()/3600).round(3), name='Delai_MED_sortie 2324'), row=1, col=8)

    fig.update_layout(height=600, width=1600, title_text="Boxplots des Durees aux Urgences (en heures) / Impact des valeurs aberrantes et outliers", title_x= 0.5)


    fig.add_annotation(
        x= 0.05,  # Coordonnee x negative pour aller Ã  gauche
        y=1.08,  # Coordonnee y au centre vertical
        text="Duree entre Entree et Sortie Urgence",  # Texte
        showarrow=False,
        font=dict(size=14, color="white"),
        xref="paper",
        yref="paper",
        textangle=0  # Texte incline verticalement
    )

    fig.add_annotation(
        x= 0.38,  # Coordonnee x negative pour aller Ã  gauche
        y=1.08,  # Coordonnee y au centre vertical
        text="Duree entre Entree et PEC IOA",  # Texte
        showarrow=False,
        font=dict(size=14, color="white"),
        xref="paper",
        yref="paper",
        textangle=0  # Texte incline verticalement
    )

    fig.add_annotation(
        x= 0.63,  # Coordonnee x negative pour aller Ã  gauche
        y=1.08,  # Coordonnee y au centre vertical
        text="Duree entre PEC IOA et PEC MED",  # Texte
        showarrow=False,
        font=dict(size=14, color="white"),
        xref="paper",
        yref="paper",
        textangle=0  # Texte incline verticalement
    )

    fig.add_annotation(
        x= 0.98,  # Coordonnee x negative pour aller Ã  gauche
        y=1.08,  # Coordonnee y au centre vertical
        text="Duree entre PEC MED et Sortie",  # Texte
        showarrow=False,
        font=dict(size=14, color="white"),
        xref="paper",
        yref="paper",
        textangle=0  # Texte incline verticalement
    )


    # Mise Ã  jour des echelles des axes Y
    fig.update_layout(
        height=600,
        width=1600,
        title_text="Boxplots des Durees aux Urgences (en heures) / Impact des valeurs aberrantes et outliers",
        title_x=0.5,
        yaxis=dict(range=[0, 30]),  # Pour le premier subplot
        yaxis2=dict(range=[0, 30]),  # Pour le deuxiÃ¨me subplot
        yaxis3=dict(range=[0, 30]),  # Pour le troisiÃ¨me subplot
        yaxis4=dict(range=[0, 30]),   # Pour le quatriÃ¨me subplot
        yaxis5=dict(range=[0, 30]),   # Pour le cinquiÃ¨me subplot
        yaxis6=dict(range=[0, 30]),   # Pour le sixiÃ¨me subplot
        yaxis7=dict(range=[0, 30]),   # Pour le septiÃ¨me subplot
        yaxis8=dict(range=[0, 30])
    )


    # Affichage dans Streamlit
    st.plotly_chart(fig, use_container_width=True)

    st.markdown("""
           Nous constatons qu'il n'y a pas de diffÃ©rences majeures sur les diffÃ©rentes durÃ©es entre 2020-2024 et 2023-2024.
            Par consÃ©quent, nous avons dÃ©cidÃ© de ne travailler que sur le dataset 2023-2024 qui a moins de donnÃ©es manquantes.
            """)

with tab2:
    st.title("ðŸ“ˆ Estimation simple par moyenne")

    df_moy = preprocess_common(df_raw.copy())
    from zoneinfo import ZoneInfo

    # Conversion forcÃ©e UTC â†’ Europe/Paris
    df_moy["Date_Heure_Entree_Sejour"] = pd.to_datetime(df_moy["Date_Heure_Entree_Sejour"], utc=True)
    df_moy["Date_Heure_Entree_Sejour"] = df_moy["Date_Heure_Entree_Sejour"].dt.tz_convert("Europe/Paris")

    # Recalcul de l'heure locale pour les graphes
    df_moy["Heure_Entree"] = df_moy["Date_Heure_Entree_Sejour"].dt.hour

    jour_mapping = {
        "Monday": "Lundi", "Tuesday": "Mardi", "Wednesday": "Mercredi",
        "Thursday": "Jeudi", "Friday": "Vendredi", "Saturday": "Samedi", "Sunday": "Dimanche"
    }
    
    import holidays
    fr_holidays = holidays.FR()
    df_moy["Date"] = df_moy["Date_Heure_Entree_Sejour"].dt.day
    df_moy["Mois"] = df_moy["Date_Heure_Entree_Sejour"].dt.month
    df_moy["jour_ferie"] = df_moy["Date_Heure_Entree_Sejour"].dt.date.isin(fr_holidays).astype(int)
    df_moy["Jour_Entree"] = df_moy["Date_Heure_Entree_Sejour"].dt.day_name().map(jour_mapping)

    nb_jours = df_moy["Date_Heure_Entree_Sejour"].dt.date.nunique()

    now = datetime.now(ZoneInfo("Europe/Paris"))

    jour_defaut = jour_mapping[now.strftime("%A")]
    date_defaut = now.day
    mois_defaut = now.month
    heure_defaut = now.hour

    st.subheader("ðŸ§ª Estimation personnalisÃ©e")

    afficher_outliers = st.toggle("Afficher les outliers", value=False, key="toggle_outliers_tab4")

    col1, col2, col3, col4 = st.columns(4)
    jours_dispos = sorted(df_moy["Jour_Entree"].dropna().unique())
    dates_dispos = sorted(df_moy["Date"].dropna().unique())
    mois_dispos = sorted(df_moy["Mois"].dropna().unique())
    heures_dispos = sorted(df_moy["Heure_Entree"].dropna().unique())

    jour = col1.selectbox("Jour", jours_dispos, index=jours_dispos.index(jour_defaut))
    date = col2.selectbox("Date (nÂ° jour)", dates_dispos, index=dates_dispos.index(date_defaut))
    mois = col3.selectbox("Mois", mois_dispos, index=mois_dispos.index(mois_defaut))
    heure = col4.selectbox("Heure", heures_dispos, index=heures_dispos.index(heure_defaut))

    def remove_outliers_iqr(df, columns, iqr_multiplier=3):
        df_filtered = df.copy()
        for col in columns:
            q1 = df_filtered[col].quantile(0.25)
            q3 = df_filtered[col].quantile(0.75)
            iqr = q3 - q1
            upper_bound = q3 + iqr_multiplier * iqr
            df_filtered = df_filtered[
                (df_filtered[col] >= 0) & (df_filtered[col] <= upper_bound)
            ]
        return df_filtered

    def calcul_moyennes_indicateurs(df, jour, date, mois, outliers=False):
        df_filtre = df[
            (df["Jour_Entree"] == jour) |
            (df["Date"] == date) |
            (df["Mois"] == mois) |
            (df["jour_ferie"] == 1)
        ]
        if not outliers:
            df_filtre = remove_outliers_iqr(df_filtre, [
                "Delai_entree_IOA_heure",
                "Delai_entree_MED_heure",
                "Duree_totale_heure"
            ])
        return {
            "IOA_moy": df_filtre["Delai_entree_IOA_heure"].mean(),
            "IOA_std": df_filtre["Delai_entree_IOA_heure"].std(),
            "MED_moy": df_filtre["Delai_entree_MED_heure"].mean(),
            "MED_std": df_filtre["Delai_entree_MED_heure"].std(),
            "TOT_moy": df_filtre["Duree_totale_heure"].mean(),
            "TOT_std": df_filtre["Duree_totale_heure"].std(),
            "filtered_df": df_filtre
        }

    res = calcul_moyennes_indicateurs(df_moy, jour, date, mois, afficher_outliers)

    col1, col2, col3 = st.columns(3)
    col1.metric("ðŸ©º IOA", f"{int(res['IOA_moy']*60)} Â± {int(res['IOA_std']*60)} min")
    col2.metric("ðŸ‘¨â€âš•ï¸ MÃ©decin", f"{int(res['MED_moy'])} Â± {int(res['MED_std'])} heures")
    col3.metric("ðŸšª Sortie", f"{int(res['TOT_moy'])} Â± {int(res['TOT_std'])} heures")

    # DonnÃ©es affluence non filtrÃ©es
    df_affluence = df_moy.groupby("Heure_Entree").agg(
        Moy_arrivees=("Duree_totale_heure", "size")
    ).reset_index()
    df_affluence["Moy_arrivees"] = df_affluence["Moy_arrivees"] / nb_jours

    # DonnÃ©es durÃ©es filtrÃ©es
    df_graph = res["filtered_df"].dropna(subset=["Duree_totale_heure"])
    df_duree = df_graph.groupby("Heure_Entree").agg(
        Duree_moy_min=("Duree_totale_heure", lambda x: x.mean())
    ).reset_index()

    # Fusion
    df_plot = pd.merge(df_duree, df_affluence, on="Heure_Entree", how="left")
    df_plot["Heure_affichage"] = df_plot["Heure_Entree"].astype(int).astype(str) + "h-" + (df_plot["Heure_Entree"] + 1).astype(int).astype(str) + "h"

    import plotly.graph_objects as go
    couleurs_barres = ["#003f7f" if h == heure else "lightblue" for h in df_plot["Heure_Entree"]]

    fig = go.Figure()

    # Barres dâ€™affluence
    fig.add_trace(go.Bar(
        x=df_plot["Heure_affichage"],
        y=df_plot["Moy_arrivees"],
        name="ArrivÃ©es moyennes",
        marker=dict(color=couleurs_barres),
        yaxis="y2",
        opacity=0.8,
        legendrank=2
    ))

    fig.add_trace(go.Scatter(
        x=df_plot["Heure_affichage"],
        y=df_plot["Duree_moy_min"],
        mode="lines+markers",
        name="DurÃ©e moyenne (heure)",
        line=dict(color="crimson", width=3),
        legendrank=1
    ))

    fig.update_layout(
        title="ðŸ“Š DurÃ©e moyenne de passage et affluence pour les paramÃ¨tres sÃ©lectionnÃ©s",
        xaxis=dict(
            title="Tranche horaire",
            tickmode="array",
            tickvals=df_plot["Heure_affichage"],
            ticktext=df_plot["Heure_affichage"],
            tickangle=0
        ),
        yaxis=dict(
            title="DurÃ©e moyenne (heure)",
            rangemode="tozero",
            autorange=True  
        ),
        yaxis2=dict(
            title="EntrÃ©es moyennes",
            overlaying="y",
            side="right",
            range=[0, 8],
            layer="below traces"  
        ),
        legend=dict(x=-0.02, y=1.06),
        bargap=0.2,
        height=500,
        template="plotly_white"
    )

    st.plotly_chart(fig, use_container_width=True)
    
def formulaire(df_base, form_key_prefix=""):
    date_entree = st.date_input("Date d'entrÃ©e", key=f"{form_key_prefix}_date_entree")
    heure_entree = st.time_input("Heure d'entrÃ©e", key=f"{form_key_prefix}_heure_entree")
    datetime_entree = datetime.combine(date_entree, heure_entree)

    age = st.number_input("Ã‚ge du patient", min_value=0, max_value=110, value=35, key=f"{form_key_prefix}_age")

    # RÃ©cupÃ©ration des motifs depuis le fichier initial
    motifs = df_raw["Motif de recours"].dropna().unique()
    motifs = sorted([m.strip() for m in motifs if m.strip() != "#VALEURMULTI"])
    motif = st.selectbox("Motif de recours", motifs, key=f"{form_key_prefix}_motif")

    # PEC IOA avec valeur actuelle par dÃ©faut
    now = datetime.now(ZoneInfo("Europe/Paris"))
    date_ioa = st.date_input("Date PEC IOA", now.date(), key=f"{form_key_prefix}_date_ioa")
    heure_ioa = st.time_input("Heure PEC IOA", now.time(), key=f"{form_key_prefix}_heure_ioa")
    datetime_ioa = datetime.combine(date_ioa, heure_ioa)

    discipline = st.selectbox("Discipline d'examen", sorted(df_base["Discipline_Examen"].dropna().unique()), key=f"{form_key_prefix}_discipline")
    type_pec = st.selectbox("Type de PEC", sorted(df_base["Type_de_PEC"].dropna().unique()), key=f"{form_key_prefix}_type_pec")
    tri_ioa = st.selectbox("Tri IOA", sorted(df_base["Tri_IOA"].dropna().unique()), key=f"{form_key_prefix}_tri_ioa")

    nb_present = st.number_input("Nombre de patients prÃ©sents", min_value=0, value=st.session_state["nb_present"], key=f"{form_key_prefix}_nb_present")
    salle_ioa = st.number_input("Patients en salle d'attente IOA", min_value=0, value=st.session_state["salle_ioa"], key=f"{form_key_prefix}_salle_ioa")
    salle_med = st.number_input("Patients en salle d'attente MED", min_value=0, value=st.session_state["salle_med"], key=f"{form_key_prefix}_salle_med")

    return {
        "Date_Heure_Entree_Sejour": datetime_entree,
        "AGE": age,
        "Motif_de_recours": motif,
        "Date_Heure_PEC_IOA": datetime_ioa,
        "Discipline_Examen": discipline,
        "Type_de_PEC": type_pec,
        "Tri_IOA": tri_ioa,
        "nombre_patients_present": nb_present,
        "Salle_attente_IOA": salle_ioa,
        "Salle_attente_MED": salle_med,
    }

with tab3:
    st.title("â±ï¸ PrÃ©diction du temps de passage total")

    with st.form("form_temps_attente"):
        col1, col2 = st.columns(2)
        now = datetime.now(ZoneInfo("Europe/Paris"))

        with col1:
            date_entree = st.date_input("Date d'entrÃ©e", value=now.date(), key="attente_date")
            heure_defaut = (now - timedelta(minutes=20)).time()
            heure_entree = st.time_input("Heure d'entrÃ©e", value=heure_defaut, key="attente_heure")
            age = st.number_input("Ã‚ge du patient", min_value=0, max_value=110, value=35, key="attente_age")
            nb_present = st.number_input("Patients prÃ©sents aux urgences", min_value=0, max_value=200, value=randint(20, 80), key="attente_present")
            nb_ioa = st.number_input("En salle d'attente IOA", min_value=0, max_value=50, value=randint(1, 10), key="attente_ioa")
            nb_med = st.number_input("En salle d'attente MÃ©decin", min_value=0, max_value=50, value=randint(2, 15), key="attente_med")

        with col2:
            date_ioa = st.date_input("Date PEC IOA", now.date(), key="attente_date_ioa")
            heure_ioa = st.time_input("Heure PEC IOA", now.time(), key="attente_heure_ioa")
            motif = st.selectbox("Motif de recours", df_raw["Motif de recours"].dropna().unique(), key="attente_motif")
            pec_options = [x for x in df_cleaned["Type_de_PEC"].unique() if isinstance(x, str) and x.strip().lower() not in ["nan", ""]]
            type_pec = st.selectbox("Type de PEC", sorted(pec_options), key="attente_pec")
            tri_options = [x for x in df_cleaned["Tri_IOA"].unique() if isinstance(x, str) and x.strip().lower() not in ["nan", ""]]
            tri_ioa = st.selectbox("Tri IOA", sorted(tri_options), key="attente_tri")
            discipline_options = [x for x in df_cleaned["Discipline_Examen"].unique() if isinstance(x, str) and x.strip() not in ["", "-", "nan"]]
            discipline = st.selectbox("Discipline Examen", sorted(discipline_options), key="attente_discipline")

        datetime_entree = datetime.combine(date_entree, heure_entree)
        datetime_ioa = datetime.combine(date_ioa, heure_ioa)

        input_data = {
            "Date_Heure_Entree_Sejour": datetime_entree,
            "Date_Heure_PEC_IOA": datetime_ioa,
            "AGE": age,
            "Motif_de_recours": motif,
            "Type_de_PEC": type_pec,
            "Tri_IOA": tri_ioa,
            "Discipline_Examen": discipline,
        }

        submitted = st.form_submit_button("PrÃ©dire (Temps avant sortie)")

    if submitted:
        model = load_model("models/model_temps_attente.pkl")
        df_input = preprocess_for_attente(df_raw.copy(), input_data)
        pred = model.predict(df_input)[0]
        st.success(f"Temps total estimÃ© avant la sortie: {round(pred, 1)} heures")

    # Comparaison des modÃ¨les de rÃ©gression
    data = {
        "ModÃ¨le": [
            "Gradient Boosting Regressor",
            "Gradient Boosting Regressor_huber",
            "XGBoost Regressor",
            "CatBoost Regressor",
            "Random_Forest",
            "Linear Regression"
        ],
        "RMSE": [5.21, 5.23, 5.10, 5.41, 5.01, 5.27],
        "MAE": [3.73, 3.61, 3.65, 3.96, 3.58, 3.83],
        "MAPE (%)": [65.7, 59.2, 63.8, 81.0, 67.8, 71.1],
        "RÂ²": [0.4, 0.4, 0.4, 0.4, 0.5, 0.4],
        "Cross-Val Score": [0.405, 0.395, 0.421, 0.359, 0.431, 0.388]
    }
    
    # CrÃ©ation du DataFrame
    df = pd.DataFrame(data)
    
      # Affichage dans Streamlit
    st.title("Comparaison des modÃ¨les de rÃ©gression")
    st.dataframe(df, use_container_width=True)

    # Affichage Image du Gradient Boosting Regressor
    image_regression_plotting = Image.open("Images/Regression_models_plotting.png")
    st.image(image_regression_plotting, width=1500)

    # Tableau Ã©valuation du modÃ¨le Gradient Boosting Regressor par Ã©chantillonage
    data = {
        "Intervalle": ["[0,2)", "[2,4)", "[4,7)", "[7,10)", "[10,20)", "[20,inf)"],
        "RMSE": [3.439739, 3.504804, 3.634573, 3.483057, 4.704146, 12.043832],
        "MAE": [2.648889, 2.581257, 2.873533, 2.759772, 3.754326, 11.115633],
        "MAPE (%)": [254.858621, 89.061865, 54.482740, 33.227294, 26.734510, 43.816827],
        "RÂ²": [-53.812927, -36.648371, -16.827149, -16.165165, -1.720196, -11.406252],
        "Cross-Val Score": [0.404729, 0.404721, 0.404784, 0.404736, 0.404801, 0.404786]
    }
    
    df = pd.DataFrame(data)
    
    st.title("Gradient Boosting regressor par Ã©chantillonage")
    st.dataframe(df)

    # Affichage Image du Gradient Boosting Regressor
    st.title("Graphe ModÃ¨le Mixte par Ã©chantionnage")
    image_Graphe_Hybride = Image.open("Images/Graphe_Hybride.png")
    st.image(image_Graphe_Hybride, width=2000)

    st.title("Transformation Logarithmique")
    image_Log_transform = Image.open("Images/Log_transformation.png")
    st.image(image_Log_transform, width=2000)
    
    image_Graphe_GBR_Log = Image.open("Images/Graphe_GBR_Log.png")
    st.image(image_Graphe_GBR_Log, width=2000)

df_comparatif_models = pd.DataFrame({
    "ModÃ¨le": [
        "Logistic Regression", "Logistic Regression",
        "Random Forest", "Random Forest",
        "Gradient Boosting", "Gradient Boosting",
        "XGBoost", "XGBoost"
    ],
    "StratÃ©gie": [
        "Sans SMOTE", "Avec SMOTE",
        "Sans SMOTE", "Avec SMOTE",
        "Sans SMOTE", "Avec SMOTE",
        "Sans SMOTE", "Avec SMOTE"
    ],
    "Accuracy": [0.7424, 0.7430, 0.8301, 0.8157, 0.8133, 0.7891, 0.8146, 0.7848],
    "Precision (Classe 1)": [0.46, 0.46, 0.70, 0.60, 0.64, 0.53, 0.64, 0.52],
    "Recall (Classe 1)": [0.79, 0.79, 0.44, 0.58, 0.41, 0.65, 0.41, 0.66],
    "F1-score (Classe 1)": [0.58, 0.58, 0.54, 0.59, 0.50, 0.58, 0.50, 0.58]
})

df_results_recall = pd.DataFrame({
    "ModÃ¨le": ["Logistic Regression", "Random Forest", "Gradient Boosting", "XGBoost"],
    "Accuracy": [0.7360, 0.7760, 0.7736, 0.7532],
    "Precision (Classe 1)": [0.45, 0.50, 0.50, 0.47],
    "Recall (Classe 1)": [0.80, 0.72, 0.71, 0.73],
    "F1-score (Classe 1)": [0.58, 0.59, 0.59, 0.57]
})

df_results_precision = pd.DataFrame({
    "ModÃ¨le": ["Logistic Regression", "Random Forest", "Gradient Boosting", "XGBoost"],
    "Accuracy": [0.7432, 0.7728, 0.8194, 0.8179],
    "Precision (Classe 1)": [0.46, 0.50, 0.62, 0.62],
    "Recall (Classe 1)": [0.78, 0.73, 0.52, 0.49],
    "F1-score (Classe 1)": [0.58, 0.59, 0.57, 0.55]
})

df_stacking_results = pd.DataFrame({
    "MÃ©trique": ["Accuracy", "Recall", "Precision", "F1-score"],
    "Score": [0.81, 0.56, 0.46, 0.51]
})

df_final_stacking_results = pd.DataFrame({
    "ModÃ¨le": ["xgb_recall", "gb_recall", "xgb_precision", "lr_precision", "rf_precision", "rf_recall"],
    "3e colonne": [0.490, 0.472, 0.467, 0.465, 0.460, 0.418],
    "Recall": [0.434, 0.400, 0.396, 0.392, 0.375, 0.312],
    "PrÃ©cision": [0.562, 0.577, 0.568, 0.572, 0.592, 0.633],
    "Accuracy": [0.840, 0.842, 0.839, 0.840, 0.843, 0.846]
})

# --- Fonction dâ€™affichage de tableau Plotly ---
def show_table_plotly(df, title):
    fig = go.Figure(data=[go.Table(
        header=dict(
            values=list(df.columns),
            fill_color='lightblue',
            align='center',
            height=35
        ),
        cells=dict(
            values=[df[col] for col in df.columns],
            fill_color='white',
            align='center',
            height=30
        )
    )])

    row_height = 30
    base_height = 80
    max_height = 500
    total_height = min(base_height + row_height * len(df), max_height)

    fig.update_layout(
        title=title,
        margin=dict(t=40, b=10),
        height=total_height
    )
    st.plotly_chart(fig, use_container_width=True)


code_preparation = '''
df=pd.read_pickle('/content/drive/MyDrive/CDA_Urgences/df_urgences_2324.pkl')

df["Delai_entree_IOA_min"] = pd.to_timedelta(((df["Date_Heure_PEC_IOA"] - df["Date_Heure_Entree_Sejour"]))).dt.total_seconds() / 60
df["Delai_IOA_MED_min"] = pd.to_timedelta(((df["Date_Heure_PEC_MED"] - df["Date_Heure_PEC_IOA"]))).dt.total_seconds() / 60
df['Delai_entree_MED_min'] = pd.to_timedelta(((df["Date_Heure_PEC_MED"] - df["Date_Heure_Entree_Sejour"]))).dt.total_seconds() / 60
df["Delai_MED_sortie_min"] = pd.to_timedelta(((df["Date_Heure_Sortie_Urgences"] - df["Date_Heure_PEC_MED"]))).dt.total_seconds() / 60
df["Duree_totale_min"] = pd.to_timedelta(((df["Date_Heure_Sortie_Urgences"] - df["Date_Heure_Entree_Sejour"]))).dt.total_seconds() / 60

# SÃ©lection des features et de la target
feats_cols = ["Type_de_PEC", "Motif_de_recours", "Tri_IOA", "Delai_entree_IOA_min",
              "Age_Moyen_Sejour_Annees", "Jour_Entree", "Heure_Entree", "nombre_patients_present",
              "Jour", "Mois", "Annee", "Semaine_Annee", "jour_ferie"]
target_col = "Hospitalisation"

X = df[feats_cols]
y = df[target_col]

# SÃ©paration des variables numÃ©riques et catÃ©goriques
numerical_features = X.select_dtypes(include=["int64", "float64", "int32", "UInt32"]).columns.tolist()
categorical_features = X.select_dtypes(include=["object"]).columns.tolist()

# Transformation des donnÃ©es AVANT SMOTE
preprocessor = ColumnTransformer([
    ("num", StandardScaler(), numerical_features),
    ("cat", OneHotEncoder(handle_unknown="ignore"), categorical_features)
])

X_transformed = preprocessor.fit_transform(X)
'''
code_eval_initial = '''
# SÃ©parer les donnÃ©es en train/test
X_train, X_test, y_train, y_test = train_test_split(X_transformed, y, test_size=0.2, random_state=42, stratify=y)

# Appliquer SMOTE uniquement sur les donnÃ©es transformÃ©es
smote = SMOTE(random_state=42)
X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)

# DÃ©finition des modÃ¨les avec class_weight et SMOTE sÃ©parÃ©s
strategies = {
    "Sans SMOTE (class_weight)": (X_train, y_train),
    "Avec SMOTE": (X_train_smote, y_train_smote)
}

models = {
    "Logistic Regression": LogisticRegression(class_weight="balanced", max_iter=1000),
    "Random Forest": RandomForestClassifier(n_estimators=200, class_weight="balanced", random_state=42),
    "Gradient Boosting": GradientBoostingClassifier(n_estimators=200, learning_rate=0.05, max_depth=5, random_state=42),
    "XGBoost": XGBClassifier(n_estimators=200, max_depth=5, learning_rate=0.05, eval_metric="logloss", use_label_encoder=False)
}

# Tester chaque stratÃ©gie (Sans SMOTE vs Avec SMOTE)
results = {}

for strat_name, (X_train_mod, y_train_mod) in strategies.items():
    print(f"\nðŸš€ **StratÃ©gie : {strat_name}** ðŸš€\n")

    for name, model in models.items():
        model.fit(X_train_mod, y_train_mod)

        y_pred = model.predict(X_test)
        accuracy = accuracy_score(y_test, y_pred)

        print(f"\nðŸ”¹ {name} ({strat_name}) ðŸ”¹")
        print(f"Accuracy: {accuracy:.4f}")
        print("Classification Report:")
        print(classification_report(y_test, y_pred))

        # Matrice de confusion
        cm = confusion_matrix(y_test, y_pred)
        plt.figure(figsize=(5, 4))
        sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", xticklabels=["Non hospitalisÃ©", "HospitalisÃ©"], yticklabels=["Non hospitalisÃ©", "HospitalisÃ©"])
        plt.xlabel("PrÃ©diction")
        plt.ylabel("VÃ©ritÃ©")
        plt.title(f"Matrice de confusion - {name} ({strat_name})")
        plt.show()

        # Stocker les rÃ©sultats
        results[f"{name} ({strat_name})"] = accuracy
'''

code_random_search_recall = '''
# DÃ©finition des modÃ¨les et paramÃ¨tres rÃ©duits pour `RandomizedSearchCV`
models_params = {
    "Logistic Regression": {
        "model": LogisticRegression(max_iter=1000),
        "params": {
            "C": np.logspace(-3, 3, 5),  # RÃ©duction du nombre de valeurs testÃ©es
            "solver": ["liblinear", "lbfgs"]
        }
    },
    "Random Forest": {
        "model": RandomForestClassifier(random_state=42),
        "params": {
            "n_estimators": [50, 100, 200],  # RÃ©duction du nombre d'estimateurs
            "max_depth": [5, 10, 15],
            "min_samples_split": [2, 5],
            "min_samples_leaf": [1, 2],
            "class_weight": ["balanced"]
        }
    },
    "Gradient Boosting": {
        "model": GradientBoostingClassifier(random_state=42),
        "params": {
            "n_estimators": [50, 100, 200],
            "learning_rate": [0.01, 0.1, 0.2],
            "max_depth": [3, 5, 10]
        }
    },
    "XGBoost": {
        "model": XGBClassifier(eval_metric="logloss", use_label_encoder=False),
        "params": {
            "n_estimators": [50, 100, 200],
            "max_depth": [3, 5, 10],
            "learning_rate": [0.01, 0.1, 0.2],
            "scale_pos_weight": [1, len(y_train_smote[y_train_smote == 0]) / len(y_train_smote[y_train_smote == 1])]
        }
    }
}

# Optimisation avec RandomizedSearchCV (10 itÃ©rations max)
best_models = {}

for name, mp in models_params.items():
    print(f"\nðŸš€ Optimisation de {name}...\n")

    search = RandomizedSearchCV(
        mp["model"], mp["params"],
        scoring="recall", cv=3, n_jobs=-1, random_state=42, n_iter=10
    )

    search.fit(X_train_smote, y_train_smote)

    best_models[name] = search.best_estimator_
    print(f"ðŸ”¹ Meilleur modÃ¨le {name}: {search.best_params_}")

# Ã‰valuation des meilleurs modÃ¨les trouvÃ©s
results = {}

for name, model in best_models.items():
    y_pred = model.predict(X_test)
    accuracy = accuracy_score(y_test, y_pred)

    print(f"\nðŸ”¹ {name} (OptimisÃ©) ðŸ”¹")
    print(f"Accuracy: {accuracy:.4f}")
    print("Classification Report:")
    print(classification_report(y_test, y_pred))

    # Matrice de confusion
    cm = confusion_matrix(y_test, y_pred)
    plt.figure(figsize=(5, 4))
    sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", xticklabels=["Non hospitalisÃ©", "HospitalisÃ©"], yticklabels=["Non hospitalisÃ©", "HospitalisÃ©"])
    plt.xlabel("PrÃ©diction")
    plt.ylabel("VÃ©ritÃ©")
    plt.title(f"Matrice de confusion - {name} (OptimisÃ©)")
    plt.show()

    # Stocker les rÃ©sultats
    results[name] = accuracy
'''

code_random_search_precision = '''
# DÃ©finition des modÃ¨les et paramÃ¨tres rÃ©duits pour `RandomizedSearchCV`
models_params = {
    "Logistic Regression": {
        "model": LogisticRegression(max_iter=1000),
        "params": {
            "C": np.logspace(-3, 3, 5),  # RÃ©duction du nombre de valeurs testÃ©es
            "solver": ["liblinear", "lbfgs"]
        }
    },
    "Random Forest": {
        "model": RandomForestClassifier(random_state=42),
        "params": {
            "n_estimators": [50, 100, 200],  # RÃ©duction du nombre d'estimateurs
            "max_depth": [5, 10, 15],
            "min_samples_split": [2, 5],
            "min_samples_leaf": [1, 2],
            "class_weight": ["balanced"]
        }
    },
    "Gradient Boosting": {
        "model": GradientBoostingClassifier(random_state=42),
        "params": {
            "n_estimators": [50, 100, 200],
            "learning_rate": [0.01, 0.1, 0.2],
            "max_depth": [3, 5, 10]
        }
    },
    "XGBoost": {
        "model": XGBClassifier(eval_metric="logloss", use_label_encoder=False),
        "params": {
            "n_estimators": [50, 100, 200],
            "max_depth": [3, 5, 10],
            "learning_rate": [0.01, 0.1, 0.2],
            "scale_pos_weight": [1, len(y_train_smote[y_train_smote == 0]) / len(y_train_smote[y_train_smote == 1])]
        }
    }
}

# Optimisation avec RandomizedSearchCV (10 itÃ©rations max)
best_models = {}

for name, mp in models_params.items():
    print(f"\nðŸš€ Optimisation de {name}...\n")

    search = RandomizedSearchCV(
        mp["model"], mp["params"],
        scoring="precision", cv=3, n_jobs=-1, random_state=42, n_iter=10
    )

    search.fit(X_train_smote, y_train_smote)

    best_models[name] = search.best_estimator_
    print(f"ðŸ”¹ Meilleur modÃ¨le {name}: {search.best_params_}")

# Ã‰valuation des meilleurs modÃ¨les trouvÃ©s
results = {}

for name, model in best_models.items():
    y_pred = model.predict(X_test)
    accuracy = accuracy_score(y_test, y_pred)

    print(f"\nðŸ”¹ {name} (OptimisÃ©) ðŸ”¹")
    print(f"Accuracy: {accuracy:.4f}")
    print("Classification Report:")
    print(classification_report(y_test, y_pred))

    # Matrice de confusion
    cm = confusion_matrix(y_test, y_pred)
    plt.figure(figsize=(5, 4))
    sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", xticklabels=["Non hospitalisÃ©", "HospitalisÃ©"], yticklabels=["Non hospitalisÃ©", "HospitalisÃ©"])
    plt.xlabel("PrÃ©diction")
    plt.ylabel("VÃ©ritÃ©")
    plt.title(f"Matrice de confusion - {name} (OptimisÃ©)")
    plt.show()

    # Stocker les rÃ©sultats
    results[name] = accuracy
'''
code_random_mlp = '''
# ParamÃ¨tres de recherche
param_distributions = {
    "hidden_layer_sizes": [(50,), (100,), (50, 25), (128, 64)],
    "alpha": [1e-5, 1e-4, 1e-3, 1e-2, 1e-1],
    "learning_rate_init": [1e-3, 1e-2, 1e-1],
    "activation": ["relu", "tanh"],
    "solver": ["adam", "sgd"]
}

# CrÃ©ation du modÃ¨le
mlp = MLPClassifier(max_iter=500, random_state=42)

# DÃ©finition du scorer basÃ© sur le recall (classe 1)
recall_scorer = make_scorer(recall_score)

# Cross-validation
cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)

# Randomized Search
search = RandomizedSearchCV(
    estimator=mlp,
    param_distributions=param_distributions,
    n_iter=30,
    scoring=recall_scorer,
    cv=cv,
    n_jobs=-1,
    verbose=1,
    random_state=42
)

# EntraÃ®nement sur les donnÃ©es SMOTE
search.fit(X_train_smote, y_train_smote)

# Meilleur modÃ¨le
best_mlp = search.best_estimator_

print("Meilleurs hyperparamÃ¨tres (RandomizedSearch - Recall):")
print(search.best_params_)
'''
code_final_optimization = '''
# ModÃ¨les fixes
gb_best_recall = GradientBoostingClassifier(
    n_estimators=200,
    max_depth=10,
    learning_rate=0.01,
    random_state=42
)

lr_best_precision = LogisticRegression(
    solver='liblinear',
    C=0.001,
    max_iter=500,
    random_state=42
)

best_mlp = MLPClassifier(
    hidden_layer_sizes=(128, 64),
    alpha=0.009485527090157502,
    learning_rate_init=0.001,
    activation='tanh',
    solver='adam',
    max_iter=500,
    random_state=42
)

def objective(trial):
    # SÃ©lection du 3e modÃ¨le Ã  tester
    third_model_name = trial.suggest_categorical("third_model", ["rf_recall", "xgb_recall", "xgb_precision", "lr_recall", "gb_precision"])

    if third_model_name == "rf_recall":
        third_model = RandomForestClassifier(n_estimators=200, max_depth=15, class_weight="balanced", random_state=42)
    elif third_model_name == "xgb_recall":
        third_model = XGBClassifier(n_estimators=50, max_depth=3, learning_rate=0.1, scale_pos_weight=1.0, use_label_encoder=False, eval_metric="logloss", random_state=42)
    elif third_model_name == "xgb_precision":
        third_model = XGBClassifier(n_estimators=200, max_depth=10, learning_rate=0.2, scale_pos_weight=1.0, eval_metric="logloss", random_state=42)
    elif third_model_name == "lr_recall":
        third_model = LogisticRegression(solver='liblinear', C=0.001, max_iter=500, random_state=42)
    elif third_model_name == "gb_precision":
        third_model = GradientBoostingClassifier(n_estimators=200, max_depth=10, learning_rate=0.1, random_state=42)

    estimators = [
        ("lr", lr_best_precision),
        ("gb", gb_best_recall),
        ("third", third_model)
    ]

    stacking = StackingClassifier(
        estimators=estimators,
        final_estimator=best_mlp,
        passthrough=False,
        n_jobs=-1
    )

    skf = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)
    y_pred = cross_val_predict(stacking, X_train_smote, y_train_smote, cv=skf)

    # Sauvegarde du nom de la combinaison et des mÃ©triques
    trial.set_user_attr("third_model", third_model_name)
    trial.set_user_attr("f1", f1_score(y_train_smote, y_pred))
    trial.set_user_attr("recall", recall_score(y_train_smote, y_pred))
    trial.set_user_attr("precision", precision_score(y_train_smote, y_pred))
    trial.set_user_attr("accuracy", accuracy_score(y_train_smote, y_pred))

    return f1_score(y_train_smote, y_pred)

study = optuna.create_study(direction="maximize", study_name="stacking_best3rd")
study.optimize(objective, n_trials=20)

# RÃ©sumÃ© des rÃ©sultats de tous les essais
print("\\nRÃ©sultats de toutes les combinaisons testÃ©es :\\n")

results = []
for t in study.trials:
    if t.values:
        results.append({
            "ModÃ¨le 3e colonne": t.user_attrs.get("third_model"),
            "F1-score": round(t.user_attrs.get("f1", 0), 3),
            "Recall": round(t.user_attrs.get("recall", 0), 3),
            "PrÃ©cision": round(t.user_attrs.get("precision", 0), 3),
            "Accuracy": round(t.user_attrs.get("accuracy", 0), 3)
        })

df_results = pd.DataFrame(results).sort_values(by="F1-score", ascending=False)
print(df_results)

print("Meilleure combinaison :")
print(study.best_trial.params)
'''
code_thresholds_optimization = '''
# CrÃ©ation du Stacking
stacking_model = StackingClassifier(
    estimators=[
        ("logreg_recall", logreg_recall),
        ("gb_precision", gb_precision),
        ("xgb_recall", xgb_recall)
    ],
    final_estimator=final_mlp,
    stack_method="predict_proba",  # On transmet les probabilitÃ©s aux modÃ¨les de base
    passthrough=False,
    n_jobs=-1
)

# ------------------------------------------------------------------------------
# EntraÃ®nement du modÃ¨le de Stacking
stacking_model.fit(X_train_transformed, y_train)

# ------------------------------------------------------------------------------
# Recherche du seuil optimal avec calcul des mÃ©triques (F1, Recall, Precision, Accuracy)

# On obtient les probabilitÃ©s prÃ©dites pour la classe positive
y_proba = stacking_model.predict_proba(X_test_transformed)[:, 1]

# CrÃ©ation d'une grille de seuils de 0.0 Ã  1.0 par pas de 0.01
thresholds = np.arange(0.0, 1.01, 0.01)
results = []

for t in thresholds:
    y_pred_temp = (y_proba >= t).astype(int)
    f1 = f1_score(y_test, y_pred_temp)
    rec = recall_score(y_test, y_pred_temp)
    prec = precision_score(y_test, y_pred_temp)
    acc = accuracy_score(y_test, y_pred_temp)
    results.append((t, f1, rec, prec, acc))

# Trier les rÃ©sultats par F1 score dÃ©croissant
results_sorted = sorted(results, key=lambda x: x[1], reverse=True)

print("\nðŸ”Ž Top 20 des seuils basÃ©s sur le F1-score (avec Recall, Precision et Accuracy) :")
print("Rank\tSeuil\tF1 Score\tRecall\tPrecision\tAccuracy")
for i, (thr, f1_val, rec_val, prec_val, acc_val) in enumerate(results_sorted[:20], start=1):
    print(f"{i}\t{thr:.2f}\t{f1_val:.3f}\t\t{rec_val:.3f}\t{prec_val:.3f}\t\t{acc_val:.3f}")
'''

# --- Affichage de lâ€™onglet PrÃ©sentation ---
with tab4:
    st.title("ðŸ¥ PrÃ©diction du risque d'hospitalisation")
    onglet_presentation, onglet_resultats, onglet_test = st.tabs(["ðŸ§  PrÃ©sentation du modÃ¨le", "ðŸ“Š RÃ©sultats du modÃ¨le", "âœª Test en conditions rÃ©elles"])

    with onglet_presentation:
        st.subheader("ðŸ§ª DÃ©marche de modÃ©lisation")

        st.markdown("### ðŸ—ƒï¸ Chargement et prÃ©paration du jeu de donnÃ©es")
        with st.expander("Voir le code"):
            st.code(code_preparation, language="python")

        st.markdown("### ðŸ” Comparaison initiale des modÃ¨les avec/sans SMOTE")
        with st.expander("Voir le code"):
            st.code(code_eval_initial, language="python")
        show_table_plotly(df_comparatif_models, "Comparaison des modÃ¨les avec et sans SMOTE")

        st.markdown("""
        On constate que l'utilisation de SMOTE permet une nette amÃ©lioration du recall et du F1 score sur l'ensemble des modÃ¨les avec un lÃ©ger recul sur la prÃ©cision.  
        Seul le modÃ¨le de rÃ©gression logistique n'est pas impactÃ©.  
        On dÃ©cide donc de conserver l'utilisation de SMOTE pour la suite.
        \n De plus, on remarque pour l'ensemble des modÃ¨les un dÃ©sÃ©quilibre entre prÃ©cision et recall.  
        On dÃ©cide donc de s'orienter vers un modÃ¨le de stacking classifier avec des modÃ¨les optimisÃ©s sur le recall et la precision afin de combiner les forces des diffÃ©rents modÃ¨les et obtenir les meilleurs rÃ©sultats possibles.
        """)

        st.markdown("### ðŸ”§ Optimisation par RandomizedSearchCV (Recall)")
        with st.expander("Voir le code"):
            st.code(code_random_search_recall, language="python")
        df_results_recall_sorted = df_results_recall.sort_values(by="Recall (Classe 1)", ascending=False)
        show_table_plotly(df_results_recall_sorted, "RÃ©sultats aprÃ¨s RandomizedSearch (Recall)")

        st.markdown("""
        La rÃ©gression logistique, aprÃ¨s optimisation, est le modÃ¨le qui montre les meilleurs performances sur le recall.
        \n Meilleur modÃ¨le Logistic Regression: {'solver': 'liblinear', 'C': np.float64(0.001)}
        """)

        st.markdown("### ðŸ”§ Optimisation par RandomizedSearchCV (PrÃ©cision)")
        with st.expander("Voir le code"):
            st.code(code_random_search_precision, language="python")
        df_results_precision_sorted = df_results_precision.sort_values(by="Precision (Classe 1)", ascending=False)
        show_table_plotly(df_results_precision_sorted, "RÃ©sultats aprÃ¨s RandomizedSearch (PrÃ©cision)")

        st.markdown("""
        On constate que XGBoost et Gradient Boosting obtiennent des rÃ©sultats Ã©quivalents en prÃ©cision aprÃ¨s optimisation.  
        Toutefois, Gradient Boosting est lÃ©gÃ¨rement meilleur que XGBoost sur les autres mÃ©triques nous allons donc le retenir comme meilleur modÃ¨le pour la precision.  
        \n Meilleur modÃ¨le Gradient Boosting: {'n_estimators': 200, 'max_depth': 10, 'learning_rate': 0.1}
        """)

        st.markdown("### ðŸ§¬ Optimisation de MLP (modÃ¨le final du stacking)")
        with st.expander("ðŸ” Pourquoi un MLP comme modÃ¨le final ?"):
            st.markdown("""
            Afin de comparer objectivement les performances des diffÃ©rentes combinaisons de modÃ¨les dans le cadre du stacking classifier, nous avons initialement testÃ© plusieurs modÃ¨les en tant que mÃ©ta-apprenants.  
            Parmi ceux-ci, le MLP (rÃ©seau de neurones multicouches) sâ€™est rapidement dÃ©marquÃ© en offrant les meilleurs rÃ©sultats globaux avant toute phase dâ€™optimisation.  

            Compte tenu de ses performances initiales, de sa capacitÃ© Ã  modÃ©liser des relations non linÃ©aires complexes entre les prÃ©dictions des modÃ¨les de base, ainsi que des rÃ©fÃ©rences disponibles dans la littÃ©rature scientifique â€” notamment en contexte mÃ©dical et en urgences hospitaliÃ¨res â€” nous avons fait le choix de **nous concentrer exclusivement sur le MLP** pour lâ€™Ã©tape dâ€™optimisation.  

            Cette approche nous a permis de garantir une Ã©valuation cohÃ©rente des diffÃ©rentes combinaisons de modÃ¨les de base tout en limitant la complexitÃ© computationnelle liÃ©e Ã  lâ€™optimisation de plusieurs mÃ©ta-modÃ¨les.
            """)

        with st.expander("ðŸ“š RÃ©fÃ©rences scientifiques"):
            st.markdown("""
            1. Neshat M, et al. *Effective Predictive Modeling for Emergency Department Visits...* arXiv:2411.11275, 2024.  
            2. *Evaluation of stacked ensemble model performance to predict clinical outcomes.* Int J Med Inform, 2023.
            """)

        with st.expander("Voir le code"):
            st.code(code_random_mlp, language="python")
        show_table_plotly(df_stacking_results, "Scores du Stacking Classifier")
        
        st.markdown("""
        Meilleur modÃ¨le MLP: {'activation': 'tanh', 'alpha': 0.009485527090157502, 'hidden_layer_sizes': (128, 64)}
        """)

        st.markdown("### ðŸš€ Optimisation finale du stacking")
        st.markdown("""
        On optimise dÃ©sormais le modÃ¨le de stacking dans son ensemble.  
        Pour cela, on garde nos meilleurs modÃ¨les sur chacune des mÃ©triques (recall et precision) ainsi que notre mlp optimisÃ© en final_estimator.
        Le but Ã©tant de tester les diffÃ©rentes combinaisons possibles pour le 3Ã¨me modÃ¨le de notre stacking afin d'obtenir les meilleurs rÃ©sultats.
        """)
        with st.expander("Voir le code"):
            st.code(code_final_optimization, language="python")
        show_table_plotly(df_final_stacking_results, "Comparaison finale des modÃ¨les optimisÃ©s")
        st.markdown("""
        Meilleure combinaison = xgb_recall.  
        On rÃ©entraine ensuite le stacking avec les meilleurs paramÃ¨tres et on fait une recherche de seuil pour trouver celui donnant les meilleurs rÃ©sultats.
        """)
        with st.expander("Voir le code"):
            st.code(code_thresholds_optimization, language="python")

        st.markdown("### ðŸ“‹ Analyse des rÃ©sultats")
        st.markdown("""
- Nette amÃ©lioration des rÃ©sultats sur le recall de la classe 1  
- Combinaison de plusieurs techniques d'optimisation (random_search, optuna, adaptation du seuil) permettant un Ã©quilibre final correct sur la classe 1 entre prÃ©cision et recall et donc un F1 score amÃ©liorÃ©  
- Scores encore insuffisant pour une prÃ©diction fiable  
- Limites de temps et de ressources ont empÃªchÃ© d'explorer plus d'options au niveau du stacking (essayer d'intÃ©grer plus de modÃ¨les, en tester d'autres ou essayer de maniÃ¨re plus poussÃ©e d'autres final_estimator)
        \n Ce modÃ¨le ne faisait pas partie de nos objectifs initiaux. Nous avons dÃ©cidÃ© de l'explorer en fin de projet face aux rÃ©sultats non satisfaisants sur les temps d'attente.  
        Nous avons toutefois rÃ©ussi Ã  obtenir des premiers rÃ©sultats encourageants. Avec plus de temps pour mieux optimiser la construction du modÃ¨le, nous aurions sans doute pu amÃ©liorer nos rÃ©sultats.  
        Dans tous les cas, ce modÃ¨le comme les autres reste limitÃ© par la qualitÃ© de nos donnÃ©es.
        """)

    with onglet_resultats:
        st.subheader("ðŸ”„ RÃ©sultats dynamiques selon le seuil")

        model_pack = load_model("models/model_hospit_v2.pkl")
        model = model_pack["model"]
        preprocessor = model_pack["preprocessor"]
        X_test = model_pack["X_test_transformed"]
        y_test = model_pack["y_test"]

        st.markdown("**Choix du seuil de classification**")
        threshold = st.slider("SÃ©lectionnez le seuil de classification :", 0.0, 1.0, 0.32, 0.01)

        y_proba = model.predict_proba(X_test)[:, 1]
        y_pred = (y_proba >= threshold).astype(int)

        col1, col2, col3, col4 = st.columns(4)
        col1.metric("F1-score", f"{f1_score(y_test, y_pred):.2f}")
        col2.metric("Recall", f"{recall_score(y_test, y_pred):.2f}")
        col3.metric("Precision", f"{precision_score(y_test, y_pred):.2f}")
        col4.metric("Accuracy", f"{accuracy_score(y_test, y_pred):.2f}")

        # Affichage cÃ´te Ã  cÃ´te : matrice + jauge F1 centrÃ©e
        col_left, col_right = st.columns(2)

        with col_left:
            center = st.columns([1, 2, 1])
            with center[1]:
                cm = confusion_matrix(y_test, y_pred)
                labels = ["Non hospitalisÃ©", "HospitalisÃ©"]
                fig_cm = go.Figure(data=go.Heatmap(
                    z=cm.tolist(),
                    x=labels,
                    y=labels,
                    colorscale='Blues',
                    showscale=False,
                    text=cm.astype(str),
                    texttemplate="%{text}",
                    hovertemplate="PrÃ©dit: %{x}<br>RÃ©el: %{y}<br>Nombre: %{z}<extra></extra>"
                ))
                fig_cm.update_layout(
                    title="Matrice de confusion",
                    xaxis_title="PrÃ©diction",
                    yaxis_title="RÃ©alitÃ©",
                    width=500,
                    height=500,
                    margin=dict(l=10, r=10, t=40, b=10)
                )
                st.plotly_chart(fig_cm, use_container_width=False)

        with col_right:
            center = st.columns([1, 2, 1])
            with center[1]:
                score_f1 = round(f1_score(y_test, y_pred) * 100, 1)
                fig_gauge = go.Figure(go.Indicator(
    mode="gauge+number",
    value=score_f1,
    domain={'x': [0, 1], 'y': [0, 1]},
    title={'text': "F1-score global (%)", 'font': {'size': 20}},
    gauge={
        'axis': {'range': [0, 100]},
        'bar': {'color': "darkblue"},
        'steps': [
            {'range': [0, 50], 'color': "lightgray"},
            {'range': [50, 70], 'color': "orange"},
            {'range': [70, 100], 'color': "lightgreen"}
        ],
        'threshold': {
            'line': {'color': "black", 'width': 4},
            'thickness': 0.75,
            'value': score_f1
        },
        'shape': "angular"
    }
))
                fig_gauge.update_layout(margin=dict(l=10, r=10, t=50, b=0), height=350)
                st.plotly_chart(fig_gauge, use_container_width=False)

    # --- Onglet 3 : Test d'un patient ---
    with onglet_test:
        st.subheader("ðŸš— Simulation d'un patient")

        with st.form("form_hospitalisation"):
            col1, col2 = st.columns(2)
            now = datetime.now(ZoneInfo("Europe/Paris"))
            heure_defaut = (now - timedelta(minutes=20)).time()

            with col1:
                date_entree = st.date_input("Date d'entrÃ©e", value=now.date(), key="hospit_date")
                heure_entree = st.time_input("Heure d'entrÃ©e", value=heure_defaut, key="hospit_heure")
                age = st.number_input("Ã‚ge du patient", min_value=0, max_value=110, value=35, key="hospit_age")
                nb_present = st.number_input("Patients prÃ©sents aux urgences", min_value=0, max_value=200, value=randint(20, 80), key="hospit_present")
                nb_ioa = st.number_input("En salle d'attente IOA", min_value=0, max_value=50, value=randint(1, 10), key="hospit_ioa")
                nb_med = st.number_input("En salle d'attente MÃ©decin", min_value=0, max_value=50, value=randint(2, 15), key="hospit_med")

            with col2:
                date_ioa = st.date_input("Date PEC IOA", now.date(), key="hospit_date_ioa")
                heure_ioa = st.time_input("Heure PEC IOA", now.time(), key="hospit_heure_ioa")
                motif = st.selectbox("Motif de recours", df_raw["Motif de recours"].dropna().unique(), key="hospit_motif")
                pec_options = [x for x in df_cleaned["Type_de_PEC"].unique() if isinstance(x, str) and x.strip().lower() not in ["nan", ""]]
                type_pec = st.selectbox("Type de PEC", sorted(pec_options), key="hospit_pec")
                tri_options = [x for x in df_cleaned["Tri_IOA"].unique() if isinstance(x, str) and x.strip().lower() not in ["nan", ""]]
                tri_ioa = st.selectbox("Tri IOA", sorted(tri_options), key="hospit_tri")
                discipline_options = [x for x in df_cleaned["Discipline_Examen"].unique() if isinstance(x, str) and x.strip() not in ["", "-", "nan"]]
                discipline = st.selectbox("Discipline Examen", sorted(discipline_options), key="hospit_discipline")

            datetime_entree = datetime.combine(date_entree, heure_entree)
            datetime_ioa = datetime.combine(date_ioa, heure_ioa)

            input_data = {
                "Date_Heure_Entree_Sejour": datetime_entree,
                "Date_Heure_PEC_IOA": datetime_ioa,
                "AGE": age,
                "Motif_de_recours": motif,
                "Type_de_PEC": type_pec,
                "Tri_IOA": tri_ioa,
                "Discipline_Examen": discipline,
                "nombre_patients_present": nb_present,
                "Salle_attente_IOA": nb_ioa,
                "Salle_attente_MED": nb_med,
            }

            submitted = st.form_submit_button("PrÃ©dire (Hospitalisation)")

        if submitted:
            model_pack = load_model("models/model_hospit_v2.pkl")
            model = model_pack["model"]
            preprocessor = model_pack["preprocessor"]

            df_input = preprocess_for_hospitalisation(df_raw.copy(), input_data)
            X = preprocessor.transform(df_input)
            proba = model.predict_proba(X)[0][1]

            bas = max(0, threshold - 0.15)
            haut = min(1, threshold + 0.15)

            # --- Affichage de la jauge ---
            fig = go.Figure(go.Indicator(
                mode="gauge+number+delta",
                value=round(proba * 100, 1),
                domain={'x': [0, 1], 'y': [0, 1]},
                title={'text': "ProbabilitÃ© d'hospitalisation", 'font': {'size': 20}},
                delta={'reference': threshold * 100, 'increasing': {'color': "red"}, 'decreasing': {'color': "green"}},
                gauge={
                    'axis': {'range': [0, 100]},
                    'bar': {'color': "darkblue"},
                    'steps': [
                        {'range': [0, bas * 100], 'color': "lightgreen"},
                        {'range': [bas * 100, haut * 100], 'color': "orange"},
                        {'range': [haut * 100, 100], 'color': "red"}
                    ],
                    'threshold': {
                        'line': {'color': "black", 'width': 4},
                        'thickness': 0.75,
                        'value': threshold * 100
                    }
                }
            ))
            st.plotly_chart(fig, use_container_width=True)

            # --- InterprÃ©tation dynamique selon la probabilitÃ© et les bornes ---
            if proba < bas:
                color = "green"
                label = "Faible risque d'hospitalisation"
            elif proba < haut:
                color = "orange"
                label = "Risque modÃ©rÃ© d'hospitalisation â€“ Ã  surveiller"
            else:
                color = "red"
                label = "Risque Ã©levÃ© dâ€™hospitalisation (Ã  confirmer)"

            st.markdown(
                f"<div style='padding: 1rem; background-color: {color}; color: white; border-radius: 0.5rem; font-weight: bold;'>"
                f"ðŸ¥ PrÃ©diction : {label}<br>ProbabilitÃ© : {round(proba*100, 1)} % (seuil {threshold})"
                f"</div>",
                unsafe_allow_html=True
            )


with tab5:
    st.markdown("## âœ… Conclusion")
    st.write("""
    Le projet a rÃ©vÃ©lÃ© des difficultÃ©s majeures liÃ©es Ã  la qualitÃ© des donnÃ©es : trop peu de variables explicatives pertinentes, beaucoup de valeurs manquantes et peu de corrÃ©lations dÃ©tectables.  
    Cela a complexifiÃ© la modÃ©lisation des temps dâ€™attente, malgrÃ© des efforts consÃ©quents en nettoyage, visualisation, et tests de modÃ¨les (rÃ©gression, classification, deep learning).  
    \n
    Nous avons aussi Ã©tÃ© confrontÃ©s Ã  des limites techniques (puissance de calcul, gestion des dÃ©pendances, Git non maÃ®trisÃ©), mais avons su y faire face en adaptant nos outils et notre organisation.
    \n
    Ce projet nous a permis de renforcer nos compÃ©tences en data science, en travaillant sur un cas rÃ©el, complexe, et en Ã©quipe. Nous avons surtout appris lâ€™importance dâ€™une bonne comprÃ©hension des donnÃ©es et dâ€™un regard critique sur les modÃ¨les.
    """)

    st.markdown("## ðŸ”§ Pistes dâ€™amÃ©lioration")
    st.write("""
    Pour amÃ©liorer la performance des modÃ¨les :  

    - IntÃ©grer des variables cliniques (signes vitaux, symptÃ´mes, antÃ©cÃ©dents)  
    - Ajouter des informations contextuelles (nombre de soignants, disponibilitÃ©s de lits, contexte social)  
    - Sâ€™inspirer des pratiques internationales (ex. : QuÃ©bec) pour enrichir les tableaux de bord  
    """)

    st.markdown("## ðŸš€ Et aprÃ¨s ?")
    st.write("""
    âœ… Le **graphique d'affluence** peut Ãªtre utilisÃ© sur le site de lâ€™Ã©tablissement ou dans la salle dâ€™attente pour **informer les patients et rÃ©guler les flux**.  
        Bien qu'il ne s'agisse pas d'un modÃ¨le de machine learning prÃ©dictif, il permet d'avoir une **visualisation statistique** des temps d'attente ajustÃ© sur la date qui peut aider Ã  **rÃ©guler les flux et contribuer Ã  l'amÃ©lioration de la satisfaction des patients**.

    ðŸ“Š Le **modÃ¨le de prÃ©diction des temps d'attente** et le **modÃ¨le de prÃ©diction dâ€™hospitalisation**, nÃ©cessitent d'Ãªtre amÃ©liorÃ©s pour une future **intÃ©gration mÃ©tier**.  
        Ils permettraient de communiquer des **temps d'attente ajustÃ©s Ã  chaque patient**, dâ€™**anticiper les besoins en lits** et dâ€™**optimiser les parcours patients**.

    Pour une mise en production rÃ©ussie :
    - **Alimentation en temps rÃ©el** des donnÃ©es depuis les SI hospitaliers (requÃªtes SQL, dÃ©pÃ´t de fichiers)
    - **IntÃ©gration dans un outil sÃ©curisÃ©** (intranet, portail dÃ©cisionnel, flux HL7 vers le DPI)
    - **Suivi rÃ©gulier des performances** des modÃ¨les
    - **Maintenance technique** : mise Ã  jour des bibliothÃ¨ques, gestion des accÃ¨s, surveillance des erreurs

    ðŸ‘‰ Une **prÃ©sentation du projet sera organisÃ©e auprÃ¨s du service des urgences** afin de **sensibiliser les Ã©quipes Ã  lâ€™importance de la qualitÃ© des donnÃ©es** et dâ€™**encourager une meilleure complÃ©tude des saisies**, indispensable Ã  lâ€™efficacitÃ© des modÃ¨les prÃ©dictifs.  
    
    Ce projet pose les bases dâ€™un outil dÃ©cisionnel utile aux urgences, Ã  condition de poursuivre lâ€™amÃ©lioration des donnÃ©es et des modÃ¨les.
    """)
